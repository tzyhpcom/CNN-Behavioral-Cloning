{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "angles = []\n",
    "samples = []\n",
    "correction = 0.25 # this is a parameter to tune\n",
    "def readFromDir(dir_name, if_windows):\n",
    "    if if_windows:\n",
    "        split_str = '\\\\'\n",
    "    else:\n",
    "        split_str = '/'\n",
    "    data_pd = pd.read_csv(dir_name+'/driving_log.csv', header=None)\n",
    "    lines = data_pd.values\n",
    "    for line in lines:\n",
    "        center_image = dir_name+'/IMG/'+line[0].split(split_str)[-1]\n",
    "        left_image = dir_name+'/IMG/'+line[1].split(split_str)[-1]\n",
    "        right_image = dir_name+'/IMG/'+line[2].split(split_str)[-1]\n",
    "#         center_image = cv2.imread(name)\n",
    "        center_angle = float(line[3])\n",
    "#         images.append(center_image)\n",
    "#         angles.append(center_angle)\n",
    "        samples.append((center_image, center_angle))\n",
    "        samples.append((left_image, center_angle+correction))\n",
    "        samples.append((right_image, center_angle-correction))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "42351\n",
      "('../behavior/behavior1/IMG/center_2017_12_16_11_41_39_478.jpg', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# get all images and angles in center \n",
    "behavior1 = '../behavior/behavior1'\n",
    "behavior2 = '../behavior/behavior2' \n",
    "behavior3 = '../behavior/behavior3'\n",
    "readFromDir(behavior1, if_windows=True)\n",
    "readFromDir(behavior2, if_windows=True)\n",
    "readFromDir(behavior3, if_windows=False)\n",
    "# print(len(images))\n",
    "print(len(angles))\n",
    "# print(images[0].shape)\n",
    "print(len(samples))\n",
    "print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(42351,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAENCAYAAADkNanAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nDAdJUo/hIEnqMRwkST2GgySp5/8DKP/AM+hzX8sAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f1fde5797f0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = np.array(samples)[:,1]\n",
    "y_train = y_train.astype(float)\n",
    "print(y_train.dtype)\n",
    "print(y_train.shape)\n",
    "hist, bins = np.histogram(y_train, bins=20)\n",
    "print()\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title(r'train size summary', fontsize=19)\n",
    "plt.savefig(\"train_size.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_array = np.array(images)\n",
    "# y_array = np.array(angles)\n",
    "# X_, y_ = shuffle(X_array, y_array)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# data_file = \"data.p\"\n",
    "# data_var = {\"X_train\":X_train, \"X_test\":X_test, \"y_train\":y_train, \"y_test\":y_test}\n",
    "\n",
    "# with open(data_file, mode='wb') as f:\n",
    "#     pickle.dump(data_var, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# transform x y direction, input original rgb image\n",
    "def transform_image(image, angle):\n",
    "    trans_range = 150\n",
    "    tx = trans_range*(np.random.uniform()-0.5)\n",
    "    ty = 10*(np.random.uniform()-0.5)\n",
    "    angle = angle + tx/trans_range*0.5  # max adjust angle 0.5\n",
    "    rows,cols,_ = image.shape\n",
    "    M = np.float32([[1,0,tx],[0,1,ty]])\n",
    "    image = cv2.warpAffine(image,M,(cols,rows))\n",
    "    return image,angle\n",
    "\n",
    "# Horizontal Flip\n",
    "def flip_image(image, angle):\n",
    "    # Horizontal Flip\n",
    "    image = cv2.flip(image, 1)\n",
    "    return image, -angle\n",
    "\n",
    "# adjust brightness\n",
    "def bright_image(image):\n",
    "    hsv = cv2.cvtColor(image, cv2.COLOR_RGB2HSV)\n",
    "    h, s, v = cv2.split(hsv)\n",
    "    v = v.astype(np.float)\n",
    "    v *= (np.random.uniform()+0.2)\n",
    "    v[v>255] = 255\n",
    "    v[v<0] = 0\n",
    "    v = v.astype(np.uint8)\n",
    "    final_hsv = cv2.merge((h, s, v))\n",
    "    image_hsv = cv2.cvtColor(final_hsv, cv2.COLOR_HSV2RGB)\n",
    "    return image_hsv\n",
    "\n",
    "# input rgb image\n",
    "def preprocess_image(image):\n",
    "    rows,cols,_ = image.shape\n",
    "#     image = cv2.cvtColor(image, cv2.COLOR_RGB2GRAY)\n",
    "#     image = cv2.equalizeHist(image)\n",
    "    image = image[50:rows-20, 0:cols]\n",
    "    image = cv2.resize(image, (64, 64), interpolation=cv2.INTER_AREA)\n",
    "    image = image/255.0 - 0.5\n",
    "#     image = np.expand_dims(image, axis=2)\n",
    "    return image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33880\n",
      "8471\n"
     ]
    }
   ],
   "source": [
    "samples = shuffle(samples)\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print(len(train_samples))\n",
    "print(len(validation_samples))\n",
    "\n",
    "def generator_train(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = batch_sample[0]\n",
    "#                 center_image = cv2.imread(name)\n",
    "                image = np.asarray(Image.open(name))\n",
    "                angle = float(batch_sample[1])\n",
    "                image, angle = transform_image(image, angle)\n",
    "                if np.random.choice([True, False]):\n",
    "                    image, angle = flip_image(image, angle)\n",
    "                image = bright_image(image)\n",
    "                image = preprocess_image(image)\n",
    "                images.append(image)\n",
    "                angles.append(angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_ = np.array(images)\n",
    "            y_ = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_, y_)\n",
    "\n",
    "            \n",
    "def generator_valid(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = batch_sample[0]\n",
    "#                 center_image = cv2.imread(name)\n",
    "                image = np.asarray(Image.open(name))\n",
    "                angle = float(batch_sample[1])\n",
    "                image = preprocess_image(image)\n",
    "                images.append(image)\n",
    "                angles.append(angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_ = np.array(images)\n",
    "            y_ = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_, y_)            \n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator_train(train_samples, batch_size=32)\n",
    "validation_generator = generator_valid(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 64, 64, 3)    0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 64, 64, 16)   64          input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 64, 64, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 32, 32, 16)   0           activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 32)   12832       max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 14, 14, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 32)   1056        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 64)   51264       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 5, 5, 64)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 5, 5, 64)     4160        max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 5, 5, 64)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 128)    0           max_pooling2d_3[0][0]            \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3200)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 3200)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          409728      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 479,233\n",
      "Trainable params: 479,233\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzyhpcom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/tzyhpcom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:59: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, callbacks=[<keras.ca..., steps_per_epoch=33880, epochs=10, validation_steps=8471)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "33879/33880 [============================>.] - ETA: 0s - loss: 0.0430Epoch 00001: val_loss improved from inf to 0.02614, saving model to model-01-0.0261.hdf5\n",
      "33880/33880 [==============================] - 5668s 167ms/step - loss: 0.0430 - val_loss: 0.0261\n",
      "Epoch 2/10\n",
      "33879/33880 [============================>.] - ETA: 0s - loss: 0.0299Epoch 00002: val_loss improved from 0.02614 to 0.02328, saving model to model-02-0.0233.hdf5\n",
      "33880/33880 [==============================] - 5664s 167ms/step - loss: 0.0299 - val_loss: 0.0233\n",
      "Epoch 3/10\n",
      "33879/33880 [============================>.] - ETA: 0s - loss: 0.0280Epoch 00003: val_loss improved from 0.02328 to 0.02082, saving model to model-03-0.0208.hdf5\n",
      "33880/33880 [==============================] - 5661s 167ms/step - loss: 0.0280 - val_loss: 0.0208\n",
      "Epoch 4/10\n",
      "33879/33880 [============================>.] - ETA: 0s - loss: 0.0271Epoch 00004: val_loss did not improve\n",
      "33880/33880 [==============================] - 5664s 167ms/step - loss: 0.0271 - val_loss: 0.0212\n",
      "Epoch 5/10\n",
      " 1222/33880 [>.............................] - ETA: 1:20:51 - loss: 0.0268"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Concatenate\n",
    "from keras.layers import Cropping2D, Input\n",
    "from keras.layers import Reshape\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "from keras.optimizers import SGD, Adam, RMSprop\n",
    "import tensorflow\n",
    "import cv2\n",
    "\n",
    "lamda_w = 1e-4\n",
    "\n",
    "# model = Sequential()\n",
    "input1 = Input(shape=(64, 64, 3))\n",
    "         \n",
    "conv1 = Conv2D(16, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(input1)\n",
    "conv1 = Activation('elu')(conv1)\n",
    "conv1 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv1)\n",
    "\n",
    "conv2 = Conv2D(32, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv1)\n",
    "conv2 = Activation('elu')(conv2)\n",
    "conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv2)\n",
    "conv3 = Activation('elu')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv3)\n",
    "conv4 = Activation('elu')(conv4)\n",
    "conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv4)\n",
    "\n",
    "conv5 = Conv2D(64, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv4)\n",
    "conv5 = Activation('elu')(conv5)\n",
    "\n",
    "merge1 = Concatenate()([conv4, conv5])\n",
    "flat1 = Flatten()(merge1)\n",
    "flat1 = Dropout(0.5)(flat1)\n",
    "\n",
    "dense1 = Dense(128, kernel_regularizer=regularizers.l2(lamda_w))(flat1)\n",
    "dense1 = Activation('elu')(dense1)\n",
    "dense1 = Dropout(0.5)(dense1)\n",
    "\n",
    "output = Dense(1)(dense1)\n",
    "\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "\n",
    "adam = Adam(lr=1e-4, beta_1=0.9, beta_2=0.999, epsilon=1e-08, decay=0.0)\n",
    "\n",
    "model.compile(loss='mse', optimizer=adam)\n",
    "model.summary()\n",
    "\n",
    "filepath=\"model-{epoch:02d}-{val_loss:.4f}.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n",
    "callbacks_list = [checkpoint]\n",
    "\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch= len(train_samples), \\\n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     nb_val_samples=len(validation_samples), \\\n",
    "                                     nb_epoch=10, verbose=1, callbacks=callbacks_list)\n",
    "model.save('model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# image1 = cv2.imread(samples[0][0])\n",
    "# image2 = Image.open(samples[0][0])\n",
    "# plt.figure()\n",
    "# plt.imshow(image1)\n",
    "# plt.figure()\n",
    "# plt.imshow(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "#     len(train_samples), validation_data = \n",
    "#     validation_generator,\n",
    "#     nb_val_samples = len(validation_samples), \n",
    "#     nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.savefig(\"loss.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
