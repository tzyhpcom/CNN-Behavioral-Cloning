{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import csv\n",
    "import cv2\n",
    "import numpy as np\n",
    "import sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn import preprocessing\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import pandas as pd\n",
    "import re\n",
    "import pickle\n",
    "from PIL import Image\n",
    "\n",
    "# Visualizations will be shown in the notebook.\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "images = []\n",
    "angles = []\n",
    "samples = []\n",
    "correction = 0.5 # this is a parameter to tune\n",
    "def readFromDir(dir_name, if_windows):\n",
    "    if if_windows:\n",
    "        split_str = '\\\\'\n",
    "    else:\n",
    "        split_str = '/'\n",
    "    data_pd = pd.read_csv(dir_name+'/driving_log.csv', header=None)\n",
    "    lines = data_pd.values\n",
    "    for line in lines:\n",
    "        center_image = dir_name+'/IMG/'+line[0].split(split_str)[-1]\n",
    "        left_image = dir_name+'/IMG/'+line[1].split(split_str)[-1]\n",
    "        right_image = dir_name+'/IMG/'+line[2].split(split_str)[-1]\n",
    "#         center_image = cv2.imread(name)\n",
    "        center_angle = float(line[3])\n",
    "#         images.append(center_image)\n",
    "#         angles.append(center_angle)\n",
    "        samples.append((center_image, center_angle))\n",
    "        samples.append((left_image, center_angle+correction))\n",
    "        samples.append((right_image, center_angle-correction))\n",
    "print(\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "42351\n",
      "('../behavior/behavior1/IMG/center_2017_12_16_11_41_39_478.jpg', 0.0)\n"
     ]
    }
   ],
   "source": [
    "# get all images and angles in center \n",
    "behavior1 = '../behavior/behavior1'\n",
    "behavior2 = '../behavior/behavior2' \n",
    "behavior3 = '../behavior/behavior3'\n",
    "readFromDir(behavior1, if_windows=True)\n",
    "readFromDir(behavior2, if_windows=True)\n",
    "readFromDir(behavior3, if_windows=False)\n",
    "# print(len(images))\n",
    "print(len(angles))\n",
    "# print(images[0].shape)\n",
    "print(len(samples))\n",
    "print(samples[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "float64\n",
      "(42351,)\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYcAAAENCAYAAADkNanAAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x7f95ae574a90>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "y_train = np.array(samples)[:,1]\n",
    "y_train = y_train.astype(float)\n",
    "print(y_train.dtype)\n",
    "print(y_train.shape)\n",
    "hist, bins = np.histogram(y_train, bins=20)\n",
    "print()\n",
    "width = 0.7 * (bins[1] - bins[0])\n",
    "center = (bins[:-1] + bins[1:]) / 2\n",
    "plt.bar(center, hist, align='center', width=width)\n",
    "plt.title(r'Augment train size summary', fontsize=19)\n",
    "plt.savefig(\"augmented_train_size.jpg\", bbox_inches='tight', pad_inches=0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# X_array = np.array(images)\n",
    "# y_array = np.array(angles)\n",
    "# X_, y_ = shuffle(X_array, y_array)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_, y_, test_size=0.2)\n",
    "\n",
    "# print(X_train.shape)\n",
    "# print(X_test.shape)\n",
    "# print(y_train.shape)\n",
    "# print(y_test.shape)\n",
    "\n",
    "# data_file = \"data.p\"\n",
    "# data_var = {\"X_train\":X_train, \"X_test\":X_test, \"y_train\":y_train, \"y_test\":y_test}\n",
    "\n",
    "# with open(data_file, mode='wb') as f:\n",
    "#     pickle.dump(data_var, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "33880\n",
      "8471\n"
     ]
    }
   ],
   "source": [
    "samples = shuffle(samples)\n",
    "train_samples, validation_samples = train_test_split(samples, test_size=0.2)\n",
    "print(len(train_samples))\n",
    "print(len(validation_samples))\n",
    "\n",
    "def generator(samples, batch_size=32):\n",
    "    num_samples = len(samples)\n",
    "    while True: # Loop forever so the generator never terminates\n",
    "        shuffle(samples)\n",
    "        for offset in range(0, num_samples, batch_size):\n",
    "            batch_samples = samples[offset:offset+batch_size]\n",
    "            images = []\n",
    "            angles = []\n",
    "            for batch_sample in batch_samples:\n",
    "                name = batch_sample[0]\n",
    "#                 center_image = cv2.imread(name)\n",
    "                center_image = np.asarray(Image.open(name))\n",
    "                center_angle = float(batch_sample[1])\n",
    "                images.append(center_image)\n",
    "                angles.append(center_angle)\n",
    "\n",
    "            # trim image to only see section with road\n",
    "            X_train = np.array(images)\n",
    "            y_train = np.array(angles)\n",
    "            yield sklearn.utils.shuffle(X_train, y_train)\n",
    "\n",
    "# compile and train the model using the generator function\n",
    "train_generator = generator(train_samples, batch_size=32)\n",
    "validation_generator = generator(validation_samples, batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 160, 320, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "cropping2d_1 (Cropping2D)       (None, 90, 320, 3)   0           input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 32, 32, 3)    0           cropping2d_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "lambda_2 (Lambda)               (None, 32, 32, 1)    0           lambda_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "lambda_3 (Lambda)               (None, 32, 32, 1)    0           lambda_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 32, 32, 16)   32          lambda_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 32, 32, 16)   0           conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 28, 28, 32)   12832       activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 28, 28, 32)   0           conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 14, 14, 32)   0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 14, 14, 32)   1056        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 14, 14, 32)   0           conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 10, 10, 64)   51264       activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 10, 10, 64)   0           conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 5, 5, 64)     0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 5, 5, 64)     4160        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 5, 5, 64)     0           conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 5, 5, 128)    0           max_pooling2d_2[0][0]            \n",
      "                                                                 activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "flatten_1 (Flatten)             (None, 3200)         0           concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "dropout_1 (Dropout)             (None, 3200)         0           flatten_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "dense_1 (Dense)                 (None, 128)          409728      dropout_1[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 128)          0           dense_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "dropout_2 (Dropout)             (None, 128)          0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "dense_2 (Dense)                 (None, 1)            129         dropout_2[0][0]                  \n",
      "==================================================================================================\n",
      "Total params: 479,201\n",
      "Trainable params: 479,201\n",
      "Non-trainable params: 0\n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tzyhpcom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: The semantics of the Keras 2 argument `steps_per_epoch` is not the same as the Keras 1 argument `samples_per_epoch`. `steps_per_epoch` is the number of batches to draw from the generator at each epoch. Basically steps_per_epoch = samples_per_epoch/batch_size. Similarly `nb_val_samples`->`validation_steps` and `val_samples`->`steps` arguments have changed. Update your method calls accordingly.\n",
      "/home/tzyhpcom/anaconda3/lib/python3.6/site-packages/ipykernel_launcher.py:53: UserWarning: Update your `fit_generator` call to the Keras 2 API: `fit_generator(<generator..., validation_data=<generator..., verbose=1, steps_per_epoch=33880, epochs=5, validation_steps=8471)`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "33880/33880 [==============================] - 3088s 91ms/step - loss: 0.0344 - val_loss: 0.0253\n",
      "Epoch 2/5\n",
      "33880/33880 [==============================] - 3077s 91ms/step - loss: 0.0289 - val_loss: 0.0242\n",
      "Epoch 3/5\n",
      " 9502/33880 [=======>......................] - ETA: 29:38 - loss: 0.0282"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Lambda, Concatenate\n",
    "from keras.layers import Cropping2D, Input\n",
    "from keras.layers import Reshape\n",
    "from keras import regularizers\n",
    "from keras import backend as K\n",
    "import tensorflow\n",
    "import cv2\n",
    "\n",
    "lamda_w = 1e-4\n",
    "\n",
    "# model = Sequential()\n",
    "input1 = Input(shape=(160,320,3))\n",
    "crop1 = Cropping2D(cropping=((50,20), (0,0)))(input1)\n",
    "resize1 = Lambda(lambda image: K.tf.image.resize_images(image, [32, 32], \\\n",
    "        method=K.tf.image.ResizeMethod.AREA))(crop1)\n",
    "gray1 = Lambda(lambda image: K.tf.image.rgb_to_grayscale(image))(resize1)\n",
    "scale1 = Lambda(lambda x: (x / 255.0) - 0.5)(gray1)\n",
    "          \n",
    "conv1 = Conv2D(16, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(scale1)\n",
    "conv1 = Activation('relu')(conv1)\n",
    "\n",
    "conv2 = Conv2D(32, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv1)\n",
    "conv2 = Activation('relu')(conv2)\n",
    "conv2 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv2)\n",
    "\n",
    "conv3 = Conv2D(32, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv2)\n",
    "conv3 = Activation('relu')(conv3)\n",
    "\n",
    "conv4 = Conv2D(64, (5, 5), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv3)\n",
    "conv4 = Activation('relu')(conv4)\n",
    "conv4 = MaxPooling2D(pool_size=(2, 2), strides=(2, 2), padding='valid')(conv4)\n",
    "\n",
    "conv5 = Conv2D(64, (1, 1), strides=(1, 1), padding='valid', kernel_regularizer=regularizers.l2(lamda_w))(conv4)\n",
    "conv5 = Activation('relu')(conv5)\n",
    "\n",
    "merge1 = Concatenate()([conv4, conv5])\n",
    "flat1 = Flatten()(merge1)\n",
    "flat1 = Dropout(0.5)(flat1)\n",
    "\n",
    "dense1 = Dense(128, kernel_regularizer=regularizers.l2(lamda_w))(flat1)\n",
    "dense1 = Activation('relu')(dense1)\n",
    "dense1 = Dropout(0.5)(dense1)\n",
    "\n",
    "output = Dense(1)(dense1)\n",
    "\n",
    "model = Model(inputs=input1, outputs=output)\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam')\n",
    "model.summary()\n",
    "history_object = model.fit_generator(train_generator, samples_per_epoch= len(train_samples), \\\n",
    "                                     validation_data=validation_generator, \\\n",
    "                                     nb_val_samples=len(validation_samples), \\\n",
    "                                     nb_epoch=5, verbose=1)\n",
    "model.save('model.h5') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# augment data with left and right images\n",
    "# with open(csv_file, 'r') as f:\n",
    "#     reader = csv.reader(f)\n",
    "#     for row in reader:\n",
    "#         steering_center = float(row[3])\n",
    "\n",
    "#         # create adjusted steering measurements for the side camera images\n",
    "#         correction = 0.2 # this is a parameter to tune\n",
    "#         steering_left = steering_center + correction\n",
    "#         steering_right = steering_center - correction\n",
    "\n",
    "#         # read in images from center, left and right cameras\n",
    "#         path = \"...\" # fill in the path to your training IMG directory\n",
    "#         img_center = process_image(np.asarray(Image.open(path + row[0])))\n",
    "#         img_left = process_image(np.asarray(Image.open(path + row[1])))\n",
    "#         img_right = process_image(np.asarray(Image.open(path + row[2])))\n",
    "\n",
    "#         # add images and angles to data set\n",
    "#         car_images.extend(img_center, img_left, img_right)\n",
    "#         steering_angles.extend(steering_center, steering_left, steering_right)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# from PIL import Image\n",
    "# import matplotlib.pyplot as plt\n",
    "\n",
    "# image1 = cv2.imread(samples[0][0])\n",
    "# image2 = Image.open(samples[0][0])\n",
    "# plt.figure()\n",
    "# plt.imshow(image1)\n",
    "# plt.figure()\n",
    "# plt.imshow(image2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from keras.models import Model\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# history_object = model.fit_generator(train_generator, samples_per_epoch =\n",
    "#     len(train_samples), validation_data = \n",
    "#     validation_generator,\n",
    "#     nb_val_samples = len(validation_samples), \n",
    "#     nb_epoch=5, verbose=1)\n",
    "\n",
    "### print the keys contained in the history object\n",
    "print(history_object.history.keys())\n",
    "\n",
    "### plot the training and validation loss for each epoch\n",
    "plt.plot(history_object.history['loss'])\n",
    "plt.plot(history_object.history['val_loss'])\n",
    "plt.title('model mean squared error loss')\n",
    "plt.ylabel('mean squared error loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['training set', 'validation set'], loc='upper right')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
